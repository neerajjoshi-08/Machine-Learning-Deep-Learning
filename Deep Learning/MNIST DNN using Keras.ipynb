{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"6. Classification_MNIST_DNN_Keras.ipynb","provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### MNIST Dataset - Deep Neural Network using Keras","metadata":{"id":"O2NbpoDwXM4H","colab_type":"text"}},{"cell_type":"code","source":"# Importing libraries.\nimport tensorflow as tf","metadata":{"id":"LFWh_byWXM4M","colab_type":"code","colab":{},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 1.Collecting dataset","metadata":{"id":"_o0IreB0XM4Y","colab_type":"text"}},{"cell_type":"code","source":"(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()","metadata":{"id":"aWTdJrn-XM4Z","colab_type":"code","colab":{},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Shape of data.\nprint('Shape of x_train', x_train.shape)\nprint('Shape of y_train', y_train.shape)","metadata":{"id":"JfZ5oAcrY3C7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"bc86df19-a50a-4cd7-a482-668aad8b2372","trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Shape of x_train (60000, 28, 28)\nShape of y_train (60000,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Value of y_train.\ny_train[0]","metadata":{"id":"-A4O6oP9ZLKR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e1b1b31a-b7bb-44f3-8a8b-a3f1d91044fa","trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"5"},"metadata":{}}]},{"cell_type":"markdown","source":"##### 2.Spliting output label into multiple values","metadata":{"id":"hqPu53UYXM4f","colab_type":"text"}},{"cell_type":"code","source":"y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes=10)","metadata":{"id":"VeZ5qk90XM4h","colab_type":"code","colab":{},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# After spliting into classes = 10.\ny_train[0]","metadata":{"id":"JV6choyEZUVU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6807069c-a816-4b89-9686-15980ffb30e2","trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"##### 3.Build the Graph","metadata":{"id":"aZl2I7XuXM4s","colab_type":"text"}},{"cell_type":"code","source":"# Clearing intial models.\ntf.keras.backend.clear_session()\n\n# Initialising Sequential model.\nmodel = tf.keras.models.Sequential()\n\n# Reshaping the data (2D to 1D) => 28x28 to 784.\nmodel.add(tf.keras.layers.Reshape((784,), input_shape=(28,28, )))\n\n# Normalizing the data.\nmodel.add(tf.keras.layers.BatchNormalization())","metadata":{"id":"qluLzxSeXM4v","colab_type":"code","colab":{},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Defining activation function.\nactivation = 'sigmoid'\n\n# Adding 1st hidden layer.\nmodel.add(tf.keras.layers.Dense(200, activation=activation))\n\n# Adding 2nd hidden layer.\nmodel.add(tf.keras.layers.Dense(100, activation=activation))\n\n# Adding 3rd hidden layer.\nmodel.add(tf.keras.layers.Dense(60, activation=activation))\n\n# Adding 4th hidden layer.\nmodel.add(tf.keras.layers.Dense(30, activation=activation))","metadata":{"id":"n6Vv8X-qXM48","colab_type":"code","colab":{},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Adding Output layer.\nmodel.add(tf.keras.layers.Dense(10, activation='softmax'))","metadata":{"id":"LlEBJRu7XM5N","colab_type":"code","colab":{},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Compiling the model.\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"id":"otz7ghtUXM5Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":178},"outputId":"f3ac5cad-069d-4c0c-8df9-32734cb44054","trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"##### 4.Reviewing model","metadata":{"id":"3Itzas6kXM5T","colab_type":"text"}},{"cell_type":"code","source":"model.summary()","metadata":{"id":"2nIecxEBXM5U","colab_type":"code","colab":{},"outputId":"e219fadc-9258-4f1d-bd75-c5fd0c7fe9e9","trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nreshape (Reshape)            (None, 784)               0         \n_________________________________________________________________\nbatch_normalization_v1 (Batc (None, 784)               3136      \n_________________________________________________________________\ndense (Dense)                (None, 200)               157000    \n_________________________________________________________________\ndense_1 (Dense)              (None, 100)               20100     \n_________________________________________________________________\ndense_2 (Dense)              (None, 60)                6060      \n_________________________________________________________________\ndense_3 (Dense)              (None, 30)                1830      \n_________________________________________________________________\ndense_4 (Dense)              (None, 10)                310       \n=================================================================\nTotal params: 188,436\nTrainable params: 186,868\nNon-trainable params: 1,568\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### 5.Training the model","metadata":{"id":"kSbT7BXuXM5X","colab_type":"text"}},{"cell_type":"code","source":"model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=32)","metadata":{"id":"EEvVeGSsXM5Y","colab_type":"code","colab":{},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Train on 60000 samples, validate on 10000 samples\nWARNING:tensorflow:From /srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/5\n60000/60000 [==============================] - 42s 708us/sample - loss: 0.6313 - acc: 0.8481 - val_loss: 0.2057 - val_acc: 0.9482\nEpoch 2/5\n60000/60000 [==============================] - 43s 710us/sample - loss: 0.1832 - acc: 0.9504 - val_loss: 0.1477 - val_acc: 0.9604\nEpoch 3/5\n60000/60000 [==============================] - 41s 675us/sample - loss: 0.1271 - acc: 0.9639 - val_loss: 0.1408 - val_acc: 0.9636\nEpoch 4/5\n60000/60000 [==============================] - 39s 647us/sample - loss: 0.1027 - acc: 0.9703 - val_loss: 0.1373 - val_acc: 0.9622\nEpoch 5/5\n60000/60000 [==============================] - 41s 682us/sample - loss: 0.0839 - acc: 0.9757 - val_loss: 0.1296 - val_acc: 0.9664\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f42a7f96d90>"},"metadata":{}}]},{"cell_type":"code","source":"# Defining activation function and using optimizer as adam with default paramters.\nactivation = 'relu'\n\n# Adding 1st hidden layer.\nmodel.add(tf.keras.layers.Dense(200, activation=activation))\n\n# Adding 2nd hidden layer.\nmodel.add(tf.keras.layers.Dense(100, activation=activation))\n\n# Adding 3rd hidden layer.\nmodel.add(tf.keras.layers.Dense(60, activation=activation))\n\n# Adding 4th hidden layer.\nmodel.add(tf.keras.layers.Dense(30, activation=activation))\n\n# Adding Output layer.\nmodel.add(tf.keras.layers.Dense(10, activation='softmax'))\n\n# Compiling the model.\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Training the model.\nmodel.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=32)","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Train on 60000 samples, validate on 10000 samples\nEpoch 1/5\n60000/60000 [==============================] - 44s 727us/sample - loss: 0.2425 - acc: 0.9254 - val_loss: 0.1733 - val_acc: 0.9556\nEpoch 2/5\n60000/60000 [==============================] - 40s 665us/sample - loss: 0.1158 - acc: 0.9636 - val_loss: 0.1770 - val_acc: 0.9636\nEpoch 3/5\n60000/60000 [==============================] - 42s 700us/sample - loss: 0.0893 - acc: 0.9720 - val_loss: 0.1578 - val_acc: 0.9667\nEpoch 4/5\n60000/60000 [==============================] - 42s 693us/sample - loss: 0.0708 - acc: 0.9779 - val_loss: 0.1511 - val_acc: 0.9693\nEpoch 5/5\n60000/60000 [==============================] - 39s 653us/sample - loss: 0.0598 - acc: 0.9811 - val_loss: 0.1570 - val_acc: 0.9715\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f42a431c5d0>"},"metadata":{}}]},{"cell_type":"code","source":"# Defining activation function and using optimizer as sgd with learning rate 0.03 and deacy = 0.001.\nactivation = 'relu'\n\n# Adding 1st hidden layer.\nmodel.add(tf.keras.layers.Dense(200, activation=activation))\n\n# Adding 2nd hidden layer.\nmodel.add(tf.keras.layers.Dense(100, activation=activation))\n\n# Adding 3rd hidden layer.\nmodel.add(tf.keras.layers.Dense(60, activation=activation))\n\n# Adding 4th hidden layer.\nmodel.add(tf.keras.layers.Dense(30, activation=activation))\n\n# Adding Output layer.\nmodel.add(tf.keras.layers.Dense(10, activation='softmax'))\n\n# Compiling the model.\noptimizer = tf.keras.optimizers.SGD(lr=0.03, decay=0.001)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Training the model.\nmodel.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=32)","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Train on 60000 samples, validate on 10000 samples\nEpoch 1/5\n60000/60000 [==============================] - 29s 478us/sample - loss: 0.3496 - acc: 0.8933 - val_loss: 0.2332 - val_acc: 0.9414\nEpoch 2/5\n60000/60000 [==============================] - 27s 452us/sample - loss: 0.1610 - acc: 0.9504 - val_loss: 0.2137 - val_acc: 0.9520\nEpoch 3/5\n60000/60000 [==============================] - 28s 472us/sample - loss: 0.1300 - acc: 0.9594 - val_loss: 0.2039 - val_acc: 0.9532\nEpoch 4/5\n60000/60000 [==============================] - 30s 505us/sample - loss: 0.1137 - acc: 0.9648 - val_loss: 0.1890 - val_acc: 0.9569\nEpoch 5/5\n60000/60000 [==============================] - 30s 501us/sample - loss: 0.1051 - acc: 0.9672 - val_loss: 0.1909 - val_acc: 0.9575\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f427464c050>"},"metadata":{}}]},{"cell_type":"code","source":"# Applying Regularization - Dropout\n\n# Defining activation function.\nactivation = 'relu'\n\n# Adding 1st hidden layer.\nmodel.add(tf.keras.layers.Dense(200, activation=activation))\n\n# Adding 2nd hidden layer.\nmodel.add(tf.keras.layers.Dense(100, activation=activation))\ntf.keras.layers.Dropout(0.4)\n\n# Adding 3rd hidden layer.\nmodel.add(tf.keras.layers.Dense(60, activation=activation))\ntf.keras.layers.Dropout(0.3)\n\n# Adding 4th hidden layer.\nmodel.add(tf.keras.layers.Dense(30, activation=activation))\n\n# Adding Output layer.\nmodel.add(tf.keras.layers.Dense(10, activation='softmax'))\n\n# Compiling the model.\noptimizer = tf.keras.optimizers.SGD(lr=0.03, decay=0.001)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Training the model.\nmodel.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=32)","metadata":{"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Train on 60000 samples, validate on 10000 samples\nEpoch 1/5\n60000/60000 [==============================] - 30s 495us/sample - loss: 0.3329 - acc: 0.8993 - val_loss: 0.2301 - val_acc: 0.9410\nEpoch 2/5\n60000/60000 [==============================] - 30s 507us/sample - loss: 0.1562 - acc: 0.9528 - val_loss: 0.2225 - val_acc: 0.9474\nEpoch 3/5\n60000/60000 [==============================] - 30s 505us/sample - loss: 0.1301 - acc: 0.9604 - val_loss: 0.2016 - val_acc: 0.9531\nEpoch 4/5\n60000/60000 [==============================] - 29s 491us/sample - loss: 0.1153 - acc: 0.9647 - val_loss: 0.1956 - val_acc: 0.9551\nEpoch 5/5\n60000/60000 [==============================] - 30s 502us/sample - loss: 0.1044 - acc: 0.9687 - val_loss: 0.1880 - val_acc: 0.9565\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f4260606150>"},"metadata":{}}]}]}